# 构建高性能Web
##一. 绪论
##工具
```
nmon
strace(在mac下时dtruss)
```
---------
##二. 数据的网络传输

---------
```
1. 分层网络模型
2. 带宽
3. 响应时间
4. 互联互通
```
**限制带宽**：`实际上就是通过限制交换机对你主机数据的接收速度来将你的发送速度牢牢控制在手的，数据链路层的流量控制是通过控制接收速度来实现的。`	
**共享带宽和独享带宽的区别**：`每时每刻的发送速度都是传输协议根据接收方的接收能力不断调整的，比如通过数据链路层或者传输层的滑动窗口协议等流量控制机制来进行速度的控制。`	
**下载中的多线程问题**`:下载的过程中需要将数据直接写入磁盘，一般的下载 进程需要将数据即时写入磁盘中，才会进行下一次接收数据的系统调用，耳穴入磁盘的过程中需要经历位于内核态内存中磁盘高速缓冲区的转发，有些下载进程（如IE）为了减少磁盘些操作的压力，会在每次接收数据的系统调用之间进行休眠停顿，这样一来，实际上单线程的下载过程中接收数据并不是绝对连贯的，所以会用多线程下载工具来加速下载，所以因为多个执行流可以使得下载过程在单位时间执行相对更多次数的数据接收系统调用，充分占用带宽。`	
**互联网运营商之间的互联互通**:`不在同一运营商的网络就需要经过骨干网络进行转发`
##三. 服务器并发处理能力
----------
```
1. 吞吐量
2. cpu并发计算
3. 系统调用
4. 内存分配
5. 持久连接
6. I/O模型
7. 服务器并发策略
```

###2. CPU 并发计算

**进程、轻量级进程（Apache的prefork模型）、线程、进程调度器、系统负载、进程切换、I/O等待、锁竞争**
####----并发用户数量
```
并发用户数：某一时刻同时向服务器发送请求的用户总数（要区分开100个用户进行10次请求和1个用户进行1000次请求的效果，因为对于同一个用户来说，连续发送请求实际上是发送一个请求并接收到响应数据后再发送下一个请求，）
```

####----最大连接数据量
```
并不是来多少用户就创建多少连接，Web服务器一般会限制同时服务的最多用户数，有时候大于服务器所维护的最大文件描述符总数，而多出来的请求，则在服务器内核的数据接收缓冲区中等待处理，所以这些请求在用户看来处于阻塞状态。
```

####----Web服务器工作的本质
```
Web服务器所做的工作的本质就是：争取以最快的速度将内核缓冲区中的用户请求数据一个不剩的都拿回去，然后尽最大努力同时快速处理完这些请求，并将相应数据放到内核维护的另一块用于发送数据的缓冲区中，接下来再尽快处理下一拨请求，并尽量让用户请求在内核缓冲区中不要等待太久。
```
**吞吐量的三个前提**: 并发用户数()、总请求数、请求资源描述   
**请求等待时间**:用户平均请求等待时间（服务器在一定并发用户数的情况下，对于单个用户的服务质量）、服务器平均请求处理时间（用于衡量服务器的整体服务质量）	

####----进程切换
```
进程拥有自己独立的内存空间，但是每个进程都只能共享CPU寄存器，一个进程被挂起的本质就是将它在CPU寄存器中的数据拿出来放入到内核堆栈中，而一个进程恢复工作的本质就是将它的数据重新导入到CPU寄存器中，这段装入和移出的数据叫做‘硬件上下文’，是进程切换的一部分，初次之外，进程上下文中还包含了进程运行时所需要的一切状态信息。
```

###3. 系统调用
 **进程通常运行在用户态，这时候可以使用CPU和内存完成一些任务，而当进程需要对硬件外设进行操作的时候（如读取磁盘文件、发送网络数据等），就必须切换到内核态，这时候它将拥有更多的权利去操控整个计算机，当在内核态的任务完成之后，进程又切回到用户态，由于系统调用涉及进程从用户态岛内核态的切换，导致一定的内存空间交换，这也属于一定程度上的上下问切换，所以系统调用的开销通常认为是比较昂贵的**
###4. 内存分配
####----Apache内存分配策略
```
Apache使用了机遇内存池的策略的内存管理方案，这种方案使得Apache在运行开始时就一次性申请大片的内存作为内存池，这样需要的时候只要在内存池中直接获取，而不需要再次分配，我们知道频繁的内存分配和释放会引发一定时间的内存整理，这本身影响了性能
```

####----Nginx内存分配策略
```
Nginx对于内存方面的良好表现，它使用多线程来处理请求，这是得多线程可以共享内存资源，从而令内存的总体使用量大大减少，另外，它使用分阶段的内存分配策略，按需分配，及时释放，使得内存使用量保持在很小的数量范围，
```

###5. 持久连接
```
持久连接的动机很简单：就是尽量减少连接次数，尽量重用连接通道
```

###6. I/O模型

####----同步阻塞I/O模型
```
同步阻塞I/O是指当进程操作涉及到某些I/O操作的系统调用或库函数时，比如accept（）、send（）、recv（）等，进程便暂停下来了，等待I/O操作完成后再继续运行，这是一种简单而有效的I/o模型，它可以和多进程结合起来有效地利用CPU资源，但是其代价就是多进程的大量内存开销。
```
####----同步非阻塞I/O
```
	在同步阻塞I/O中，进程实际等待的时间可以包括两部分，一个时等待数据的就绪，另一个时等待数据的复制，对于网络I/O来说，前者的时间可能会更长一点，
	同步非阻塞I/O的调用不会等待数据的就绪，如果数据不可读或者不可写，它会立即告诉进程，比如使用recv（）接收网络数据的时候，如果网卡缓冲区中没有可接收的数据，函数就及时返回，告诉进程没有数据可读了，相比于阻塞I/O，这种非阻塞I/O结合反复轮序来尝试数据是否就绪，防止进程被阻塞，最大的好处就是可以在一个进程中同时处理多个I/O操作，
	非阻塞I/O一半只针对于网络I/o有效，我们只要在socket的选项设置中使用O_NONBLOCK即可，这样对于改socket的send()或recv()便采用非阻塞方式，值得注意的是，对于磁盘I/O，非阻塞I/O并不产生效果。
```
####----多路I/O就绪通知
 **多路I/O就绪通知的出现，提供了对大量文件描述符就绪检查的高性能方案，它允许进程通过一种方法来同时监视所有文件描述符，并可以快速获得所有就绪的文件描述符，然后只针对于这些文件描述符进行数据访问，就访问数据本身而言，仍然需要选择阻塞或者非阻塞的访问方式，一般我们选择非阻塞的方式，以防止任何意外的等待阻塞整个进程，比如有时就绪通知只代表了一个内核的提示，也许此时文件描述符尚未真正准备好或者已经被客户端关闭连接**	
 
1. **select**

```
	它通过一个select()系统调用来监视包含多个文件描述符的数组，当select()返回后，该书组中就绪的文件描述符便会被内核修改标志位，当select()返回后，该数组中就绪的文件描述符便会被内核修改标志位，使得进程可以获得这些文件描述符从而进行后续的读写操作	
	select的一个缺点时单个进程能够监视的文件描述符的数量存在最大限制，在linux上一般为1024，不过可以通过修改宏定义伸直重新编译内核的方式提升这一限制，另外select()所维护的存储大量文件描述符的数据结构，随着文件描述符数量的增大，其复制的开销也线性增长，同时，由于网络响应时间的延迟使得大量TCP连接处于非活跃状态 ，但调用select()会对所有socket进行一次线性扫描，所以这也是浪费了一定的开销	
```

2. **poll**

```
	select 和poll没有本质上的区别，但是poll没有醉倒文件描述符数量的限制，select和poll同样存在一个缺点就是当大量文件描述符的数组被整体复制与用户态和内核态的地址空间之间的时候，不论这些文件描述符是否就绪，它的开销随着文件描述符数量的增加而线性增大
	同时两个都采用水平触发的方式：select和poll将就绪的文件描述符告诉进程后，如果进程没有对其进行操作，那么下次调用的时候，将再次报告这些文件描述符，所以一般不会丢失就绪的消息。
```

3. **SIGIO**

```
	通过实时信号来实现select／poll的通知方法，但是它们的不同在于，select/poll告诉我们哪些文件描述符是就绪的，一直到我们读写它之前，每次select／poll都会告诉我们，而SIGIO则是告诉我们哪些文件描述符刚刚变为就绪状态，只说一次，如果我们不采取行动，那么它就不会告知，这种方式叫做边缘触发
	缺点：1，代表事件的信号由内核中的事件队列来维护，信号按照顺序进行通知，这可能导致当一个信号到达的时候，这事件已经过期，它所描述的文件描述符已经关闭，2，事件队列的长度是有限制的，无论你设置多大的上限，总会被放满，这就很容易发生事件丢失，
```

4. **/dev/poll**

```
	使用了虚拟设备，可以将要监视的文件描述符数组写入到设备中，然后通过ioctl()来等待事件通知，当ioctl()返回就绪的文件描述符后，你可以从／dev/poll中读取所有就绪的文件描述符数组，这点类似于SIGIO，节省了扫描所有文件描述符的开销
```

5. **epoll**
主要的优势是1. 内存复制（poll select每次收集时间的时候，都要把连接的套接字传送给操作系统，涉及到从用户态到内核态的大量复制，，）2. 驱动程序建立回调关系（epoll采用了红黑树实现，并且建立回调关系）

```
	epoll可以支持水平触发和边缘触发，理论上边缘触发的性能更高一点，在默认情况下，epoll采用的是水平出发，如果需要使用边缘触发，则需要在事件注册时增加EPOLLET选项，Lighttpd的俄 poll模型代码中注释掉了EPOLLET，采用的是水平出发，Nginx使用的是边缘触发：
					ee.events = EPOLLIN|EPOLLOUT|EPOLLET;
epoll同样只告知那些就绪的文件描述符，而且当我们调用epoll_wait获得就绪文件描述符时，返回的并不是实际的文件描述符，而是代表就绪描述符数量的值，你只需要去epoll指定的一个数组中依次去处相应数量的文件描述符即可，
	这里也使用了内存映射技术，这样更彻底省掉了这些文件描述符在系统调用中的复制开销，
	另一个本质的改进在于epoll采用基于事件的就绪通知方式，在select/poll中，进程只有在调用一定的方法后，内核才对所有监视的文件描述符进行描述，而epoll事先通过epoll_ctl()来注册一个文件描述符，一旦某个文件描述符就绪时，内核会采用callback的回调机制，迅速激活这个文件描述符，当进程调用epoll_wait()时便得到通知
```
####----内存映射
```
可以将内存中某块地址空间和我们指定的磁盘文件相关联，从而把我们对这块内存的访问转换为对磁盘文件的访问，有两种类型的内存映射：
	1. 可以讲任何对内存的写操作都同步到磁盘文件，并且所有映射同一文件的进程都共享任意一个进程对映射内存的修改
	2. 映射的文件是只读文件，所以多个进程不共享修改
```
####直接I/O
```
	内存映射和直接访问文件没有本质上的差别，因为数据从进程用户态内存空间到磁盘都需要经过两次复制，即在磁盘与内核缓冲区之间以及在内核缓冲区与用户态内存空间，引入内核缓冲区的目的在于提高磁盘访问文件的性能（如果文件内容已经在内核缓冲区中，那么就不需要再次访问磁盘，写入数据的时候，实际上只是写入到了内核缓冲区中，便告诉进程已经写入成功）
	对于一些较复杂的应用，比如数据库服务器，为了充分提高性能，希望绕过内核缓冲区，由自己在用户带空间实现并且管理I/O缓冲区，包括缓存机制和写延迟机制等，另一方面，绕过内核缓冲区也剋减少系统内存的开销，因为内核缓冲区本身就在使用系统内存。
	在open() 系统调用中增加参数O_DIRECT，用它打开的文件便可以绕过内核缓冲区直接访问，这样便有效避免了CPU和内存的多余时间开销。
```

####----sendfile
```
	大多数时候，我们都在向Web服务器请求静态文件，比如图片、样式表等，根据前面的介绍，我们知道在这些请求的过程中，磁盘文件的数据先要经过内核缓冲区，然后到达用户空间，因为是不需要任何处理的静态数据，所以它们又被送到网卡对应的内核缓冲区，接着再被送入网卡进行发送。
	同时，Linux通过系统调用将这种机制提供给开发者，那就是sendfile()系统调用，它可以将磁盘文件的特定部分直接传送给代表客户端的socket描述符，加快了静态文件的请求速度，同时减少了CPU和内存的开销。
```
####异步I/O
```
阻塞和非阻塞：当进程访问的数据如果上位就绪，进程是否需要等待，简单说相当于函数内部的实现区别，即为就绪是直接返回还是等待就绪，
同步和异步：访问数据的机制，同步一半值主动请求并且等待I/O操作完毕的方式，当数据就绪后在读写的时候必须阻塞，异步指的是主动请求数据后便可以继续处理其他任务，随后等待I/O操作完毕的通知，这可以使进程在数据读写时不发生阻塞
```
###7. 服务器并发策略
**从本质上来讲，所有到达服务器的请求兜风装载IP包中，位于网卡的接收缓冲区中，这时候Web服务器软件要做的事情就是不断地读取这些请求，然后进行处理，将结果写到发送缓冲区中，其中包含了一系列的I/O操作和CPU计算，而设计一个并发策略的目的就是让I/O模型和CPU计算尽量重叠进行，以防 main让CPU在I/O等待中不要空闲，另一方面让CPU在I/O调度上尽量花费最少的时间**
1. 一个进程处理一个连接，非阻塞I/O
2. 一个线程处理一个连接，非阻塞I/O
3. 一个进程处理多个连接，非阻塞I/O
4. 一个线程处理多个连接，异步I/O

####----一个进程处理一个连接
```
	fork模式，由主进程负责accept()来自客户端的连接，一旦接受连接，便马上fork（）一个新的worker进程来处理，处理结束后，这个进程便被销毁，
	prefork模式，这种方式由主进程预先创建一定数量的子进程，每个请求有一个子进程来处理，但是每个子进程可以处理多个请求，父进程往往只负责管理子进程，根据站点符在来调整子进程的数量，相当于动态维护了一个进程池
	对于accept（）的方式，有以下两种策略：
	1. 主进程使用非阻塞accept（）来接收连接，当建立连接，主进程将任务分配给空闲的子进程来处理
	2. 所有子进程使用阻塞accept()来竞争接收连接，一旦一个子进程建立连接，它将继续进行处理。
    在这种阻塞竞争的情况下，虽然从代码上看似只有一个子进程的accept()可以返回，但实际上，按大多数TCP栈的实现方法，当一个请求连接到达时，内核会激活所有阻塞在accept()的子进程，但只有一个能够成功获得连接并返回到用户空间，而其余的子进程由于得不到连接而继续回到休眠状态，这种‘抖动’也造成一定的额外开销。
```

####----一个线程处理一个连接，非阻塞I/O
```
	Apache的worker多路处理模块便采用了这种方式，它的主要目的是在于减少prefork模式中太多进程的开销，是Apache可以支持更多的并发连接，worker模型可以说是一种多进程和多线程的混合方式，在世纪测试中，这种方式的表现并不比prefork有太大的优势，虽然它使用大量线程代替进程，但是这些线程实际上都是由内核进程调度管理的轻量级进程，它们的上下文切换开销依然存在。
```
####----一个进程处理多个连接，非阻塞I/O
```
一个进程处理多个连接，存在一个潜在条件，就是多路I/O就绪通知的应用，多路I/O就绪通知的性能就成为了关键，select和poll都是采用对所有文件描述符采用轮询的方式进行的，而epoll则不是，select由于连接有1024个限制，当存在大量非活跃连接的时候，epoll的优势就会不言而喻。
```

##四. 动态内容缓存
```
1. 重复的开销
2. 缓存与速度
3. 页面缓存
4. 局部无缓存
5. 静态化内容
```

**局部无缓存**:`对于有些特殊的动态网页，需要页面中某一块区域的内容及时更新，比如一个新闻征文页面的阅读量统计区域和评论区域，如果为了这一块区域的及时更新，就将整个页面重新创建缓存的话，的确有点不值得，在流行的模版框架中，在整页缓存的基础上，都提供了局部无缓存的支持，它允许在页面中指定一块包含动态数据的HTML代码段，每次这些动态数据都需要实时计算，然后喝其余部分的缓存合成最终的网页`

##五. 动态脚本加速
```
1. opcode缓存（operate code）(对中间结果进行缓存，不需要每次计算)
2. 解释器扩展模块
3. 脚本跟踪与分析
```

编译器和解释器的一个`本质不同`是解释器在生成中间代码后，便直接执行它，所以运行时的控制权在解释器，而编译器则将中间代码进一步优化，生成可以直接运行的目标程序，但不执行它，用户可以在随后的任意时间执行它，这时控制权权在目标程序，和编译器没有任何关系。

**动态脚本加速**：`通过动态内容的计算结果生成缓存，达到了一定的目的，那就是最大程度地跳过动态内容计算，然而，除非静态化访问，否则完全跳过动态内容的计算是不可能的，加载缓存仍然需要动态脚本的运行为了提高动态内容的处理速度，本章做了什么？`

##六. 浏览器缓存（节省带宽的意义更大一点）
Firefox浏览器在使用磁盘来存储缓存文件的同时，还使用了内存，它将命中率较高的缓存内容同时也装入到内存中，这样浏览器在查找缓存的时候 ，将先在高速内存中查找，如果内存中没有需要的缓存，便前往磁盘缓存目录中继续查找。

```
1. 别忘了浏览器	
2. 缓存协商	
3. 彻底消灭请求	
```

传输13000字节的I/O开销相比于动态程序份检查和加载缓存的计算开销来说算不上什么

 **协商的一个过程**：
 
 ```
 时间协商：
 1. 浏览器请求资源
 2. 服务器返回的请求头中多了 Last－Modified信息
 3. 浏览器访问时的请求中多了 If－Modified－Since信息
 4. 304 Not Modified信息（意味着Web服务器高速浏览器，这个内容并没有更新，浏览器可以使用本地缓存的内容，同时，Web服务器没有将内容的征文传给浏览器）
 Etag协商（没有采用内容的最后修改时间，而是采用了一串编码来标记内容）：
 1. 浏览器发出请求
 2. 服务器返回的请求头中多了 ETag：标签信息
 3. 浏览器发起的请求中包含了If－None－Match（服务器需要讲自己的ETag值和HTTP请求中的ETag值进行比较，如果相同的话，便返回304状态码，如果不同的话，则将最新的内容返回给浏览器）
 ```
 
 **彻底消除缓存**:使用Expires标志，高速浏览器该内容在何时过期，暗示浏览器在该内容过期之前不需要再询问服务器，而直接使用本地缓存即可。
 
 **如何请求页面**：
 
 ```
 	Ctrl+F5:这种方式可以叫强制刷新，它使得网页以及其中的所有组件都直接向Web服务器发送请求，并且不使用缓存协商，这样的目的是获取所有内容的最新版本，
 	F5:这种方式是一般的刷新，等同于单击浏览器的刷新按钮，允许浏览器在请求中附加必要的缓存协商，但不允许浏览器直接使用本地缓存，也就是说能够让Last－Modified发挥效果，但是对Expires无效
 	单击浏览器的转到（这种相当于输入了URL按回车键）：允许浏览器以最少的请求来获取网页的数据，浏览器会对所有没有过期的内容直接食用本地缓存，所以，Expires标记只对这种方式有效，
 ```
 
 为了适应本地过期时间,浏览器和服务器的时间不同步和时区问题，使用了Cache－Control：max-age=<second>指定了缓存的相对时间，并且这个时间是相对于浏览器本地时间而言的。目前的主流浏览器都将HTTP／1.1作为首选，所以当HTTP响应头中同时含有Expires和Cache－Control时，浏览器会优先使用Cache－Control，

##七. Web服务器缓存
```
1. URL 映射
2. 缓存响应内容
3. 缓存文件描述符
```

##八. 反向代理缓存
```
1. 传统代理
2. 何为反向
3. 在反向代理上创建缓存
4. 小心穿过代理
5. 流量分配
```
##九. Web组件分离
```
1. 备受争议的分离
2. 因材施教
3. 拥有不同的域名（比如img 和upload 分别指向不同的域名，要关注的是不同域名之下的cookie范围）
4. 浏览器并发数
5. 发挥各自的潜力
```
浏览器的最大并发数量针对的是单个站点（域名），浏览器会为每个域名维护不同的下载队列，每个队列的最大并发数限制根据浏览器的不同而不同，但是每个域名下的队列可以同时运行，这样一来，浏览器的下载并发数就会增多，整体下载速度也会提高。

**我们从以下方面看Web组件的差异性**：	
1. 文件大小		
2. 文件数量		
3. 内容更新频率		
4. 预计并发用户数		
5. 是否需要脚本解释器		
6. 是否涉及大量的CPU计算		
7. 是否访问数据库		
8. 访问数据库的主要操作是读还是写		
9. 是否包含远程调用


**考虑以下优化方法：**
1. 是否使用epoll模型
2. 是否使用sendfile（） 系统调用
3. 是否使用异步I/O
4. 是否支持HTTP持久连接
5. 是否需要opcode缓存
6. 是否使用动态内容缓存以及有效期多长
7. 是否使用Web服务器缓存以及有效期多长
8. 是否使用浏览器缓存以及有效期多长
9. 是否使用反向代理缓存以及有效期多长
10. 是否使用负载均衡策略

 **动态内容**
 ```
 开启opcode缓存
 足够多的CPU
 足够大的内存
 多进程
 与数据库保持高速连接
 可靠的数据中心
 ```
 
 **静态网页**
 静态网页也就是直接存储在服务器磁盘上的HTML文档，它和其他静态内容一样，都不需要动态脚本解释器的参与，所以节省了一定的CPU和内存开销，同时，它们需要全身心地进行I/O操作，时I/O密集型操作，除了静态网页之外，静态内容还包含图片、样式表等，与动态内容不同的是，静态内容的吞吐率很大程度上取决于服务器的并发处理能力，
 
 ```
 epoll(使得Web服务器在大量并发用户数的情况下保持较稳定的吞吐率)
 非阻塞（避免不必要的I/O等待）
 异步I/O（如果可能的话，使用真正意义上的异步I/O）
 使用sendfile()系统调用
 避免多进程切换的不必要开销，对于磁盘I/O密集型的静态内容处理，多进程不能带来多大的意义
 使用高速磁盘
 使用RAID分区
 购买足够的带宽
 充分使用浏览器缓存
 ```
 
 
##十. 分布式缓存
```
1. 数据库的前端缓存
2. 使用memcached
3.  读操作缓存
4.  写操作缓存
5.  监控状态
6.  缓存扩展
```

##十一. 数据库性能优化
```
1. 友好的状态报告
2. 正确使用索引
3. 锁定与等待
4. 事务性表的性能
5. 使用查询缓存
6. 临时表
7. 线程池
8. 反范式设计
9. 放弃关系型数据库
```
##十二. Web负载均衡
```
1. 一些思考
2. HTTP重定向
3. DNS负载均衡
4. 反向代理负载均衡
5. IP负载均衡
6. 直接路由
7. IP隧道
8. 考虑可用性
```




















